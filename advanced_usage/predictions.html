<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Using MALA in production &mdash; Materials Learning Algorithms (MALA)  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=33f2f6c7" />

  
    <link rel="shortcut icon" href="../_static/mala_favicon.png"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=5929fcd5"></script>
        <script src="../_static/doctools.js?v=9a2dae69"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Citing MALA" href="../citing.html" />
    <link rel="prev" title="Improved hyperparameter optimization" href="hyperparameters.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html">
            
              <img src="../_static/mala_horizontal_white.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic_usage.html">Getting started with MALA</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../advanced_usage.html">Advanced options</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="trainingmodel.html">Improved training performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="openpmd.html">Storing data with OpenPMD</a></li>
<li class="toctree-l2"><a class="reference internal" href="descriptors.html">Improved data conversion</a></li>
<li class="toctree-l2"><a class="reference internal" href="hyperparameters.html">Improved hyperparameter optimization</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Using MALA in production</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#predictions-on-gpus">Predictions on GPUs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#parallel-predictions">Parallel predictions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#visualizing-observables">Visualizing observables</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../citing.html">Citing MALA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CONTRIBUTE.html">Contributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/modules.html">API reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Materials Learning Algorithms (MALA)</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../advanced_usage.html">Advanced options</a></li>
      <li class="breadcrumb-item active">Using MALA in production</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com//mala-project/mala/blob/develop/docs/source/advanced_usage/predictions.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="using-mala-in-production">
<span id="production"></span><h1>Using MALA in production<a class="headerlink" href="#using-mala-in-production" title="Link to this heading"></a></h1>
<p>MALA is aimed at providing ML-DFT models for large scale investigations.
Predictions at scale in principle work just like the predictions shown
in the basic guide. One has to set a few additional parameters to make
optimal use of the hardware at hand.</p>
<p>As a general remark please be reminded that if you have not used LAMMPS
for your first steps in MALA, and instead used the python-based descriptor
calculation methods, we highly advise switching to LAMMPS for advanced/more
involved examples (see  <a class="reference internal" href="../install/installing_lammps.html#lammpsinstallation"><span class="std std-ref">installation instructions for LAMMPS</span></a>).</p>
<p>MALA ML-DFT models can be used for predictions at system sizes and temperatures
larger resp. different from the ones they were trained on. If you want to make
a prediction at a larger length scale then the ML-DFT model was trained on,
MALA will automatically determine a suitable realspace grid for the prediction.
You can manually specify the inference grid if you wish via</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predictor class</span>
<span class="n">parameters</span><span class="o">.</span><span class="n">running</span><span class="o">.</span><span class="n">inference_data_grid</span> <span class="o">=</span> <span class="o">...</span>
<span class="c1"># ASE calculator</span>
<span class="n">calculator</span><span class="o">.</span><span class="n">mala_parameters</span><span class="o">.</span><span class="n">running</span><span class="o">.</span><span class="n">inference_data_grid</span> <span class="o">=</span> <span class="o">...</span>
</pre></div>
</div>
</div></blockquote>
<p>Here you have to specify a list with three entries <code class="docutils literal notranslate"><span class="pre">[x,y,z]</span></code>. As matter
of principle, stretching simulation cells in either direction should be
reflected by the grid.</p>
<p>Likewise, you can adjust the inference temperature via</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predictor class</span>
<span class="n">predictor</span><span class="o">.</span><span class="n">predict_for_atoms</span><span class="p">(</span><span class="n">atoms</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=...</span><span class="p">)</span>
<span class="c1"># ASE calculator</span>
<span class="n">calculator</span><span class="o">.</span><span class="n">data_handler</span><span class="o">.</span><span class="n">target_calculator</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="o">...</span>
</pre></div>
</div>
</div></blockquote>
<section id="predictions-on-gpus">
<span id="production-gpu"></span><h2>Predictions on GPUs<a class="headerlink" href="#predictions-on-gpus" title="Link to this heading"></a></h2>
<p>MALA predictions can be run entirely on a GPU. For the NN part of the workflow,
this seems like a trivial statement, but the GPU acceleration extends to
descriptor calculation and total energy evaluation. By enabling GPU support
with</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">parameters</span><span class="o">.</span><span class="n">use_gpu</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
</div></blockquote>
<p>prior to an ASE calculator calculation or usage of the <code class="docutils literal notranslate"><span class="pre">Predictor</span></code> class,
all computationally heavy parts of the MALA inference, will be offloaded
to the GPU. Please note that this requires LAMMPS to be installed with GPU, i.e., Kokkos
support. Multiple GPUs can be used during inference by first enabling
parallelization via</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">parameters</span><span class="o">.</span><span class="n">use_mpi</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
</div></blockquote>
<p>and then invoking the MALA instance through <code class="docutils literal notranslate"><span class="pre">mpirun</span></code>, <code class="docutils literal notranslate"><span class="pre">srun</span></code> or whichever
MPI wrapper is used on your machine. Details on parallelization
are provided <a class="reference internal" href="#production-parallel"><span class="std std-ref">below</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To use GPU acceleration for total energy calculation, an additional
setting has to be used.</p>
</div>
<p>Currently, there is no direct GPU acceleration for the total energy
calculation. For smaller calculations, this is unproblematic, but it can become
an issue for systems of even moderate size. To alleviate this problem, MALA
provides an optimized total energy calculation routine which utilizes a
Gaussian representation of atomic positions. In this algorithm, most of the
computational overhead of the total energy calculation is offloaded to the
computation of this Gaussian representation. This calculation is realized via
LAMMPS and can therefore be GPU accelerated (parallelized) in the same fashion
as the bispectrum descriptor calculation. If a GPU is activated (and LAMMPS
is available), this option will be used by default. It can also manually be
activated via</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">parameters</span><span class="o">.</span><span class="n">use_atomic_density_formula</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
</div></blockquote>
<p>The Gaussian representation algorithm is describe in
the publication <a class="reference external" href="doi.org/10.1038/s41524-023-01070-z">Predicting electronic structures at any length scale with machine learning</a>.</p>
</section>
<section id="parallel-predictions">
<span id="production-parallel"></span><h2>Parallel predictions<a class="headerlink" href="#parallel-predictions" title="Link to this heading"></a></h2>
<p>MALA predictions may be run on a large number of processing units, either
CPU or GPU. To do so, simply enable MPI usage in MALA</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">parameters</span><span class="o">.</span><span class="n">use_mpi</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
</div></blockquote>
<p>Once MPI is activated, you can start the MPI aware Python script using
<code class="docutils literal notranslate"><span class="pre">mpirun</span></code>, <code class="docutils literal notranslate"><span class="pre">srun</span></code> or whichever MPI wrapper is used on your machine, for
example with</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --nodes=NUMBER_OF_NODES</span>
<span class="c1">#SBATCH --ntasks-per-node=NUMBER_OF_TASKS_PER_NODE</span>
<span class="c1">#SBATCH --gres=gpu:NUMBER_OF_TASKS_PER_NODE</span>
<span class="c1"># Add more arguments as needed</span>
...

<span class="c1"># Load more modules as needed</span>
...

<span class="c1"># Depending on your cluster setup, you may need to use srun here</span>
<span class="c1"># rather than mpirun.</span>
<span class="c1"># Note that</span>
<span class="c1"># NUMBER_OF_RANKS = NUMBER_OF_NODES * NUMBER_OF_TASKS_PER_NODE</span>
mpirun<span class="w"> </span>-np<span class="w"> </span>NUMBER_OF_RANKS<span class="w"> </span>python3<span class="w"> </span>-u<span class="w"> </span>prediction.py
</pre></div>
</div>
</div></blockquote>
<p>By default, MALA can only operate with a number of processes by which the
z-dimension of the inference grid can be evenly divided, since the Quantum
ESPRESSO backend of MALA by default only divides data along the z-dimension.
If you, e.g., have an inference grid of <code class="docutils literal notranslate"><span class="pre">[200,200,200]</span></code> points, you can use
a maximum of 200 ranks. Using, e.g., 224 CPUs will lead to an error.</p>
<p>Parallelization can further be made more efficient by also enabling splitting
in the y-dimension. This is done by setting the parameter</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">parameters</span><span class="o">.</span><span class="n">descriptors</span><span class="o">.</span><span class="n">use_y_splitting</span> <span class="o">=</span> <span class="n">ysplit</span>
</pre></div>
</div>
</div></blockquote>
<p>to an integer value <code class="docutils literal notranslate"><span class="pre">ysplit</span></code> (default: 0). If <code class="docutils literal notranslate"><span class="pre">ysplit</span></code> is not zero,
each z-plane will be divided <code class="docutils literal notranslate"><span class="pre">ysplit</span></code> times for the parallelization.
If you, e.g., have an inference grid of <code class="docutils literal notranslate"><span class="pre">[200,200,200]</span></code>, you could use
400 processes and <code class="docutils literal notranslate"><span class="pre">ysplit</span></code> of 2. Then, the grid will be sliced into 200
z-planes, and each z-plane will be sliced twice, allowing even faster
inference.</p>
</section>
<section id="visualizing-observables">
<h2>Visualizing observables<a class="headerlink" href="#visualizing-observables" title="Link to this heading"></a></h2>
<p>MALA also provides useful functions to visualize observables, as shown in
the file <code class="docutils literal notranslate"><span class="pre">advanced/ex08_visualize_observables</span></code>. To calculate observables
for analysis and visualization, you need an LDOS calculator object.
If you perform ML-DFT inference, you will get this object from the
<code class="docutils literal notranslate"><span class="pre">Predictor</span></code> resp. ASE calculator object, but it can also be created by
itself, as shown in the mentioned example file.</p>
<p>Having obtained an LDOS calculator object, you can access several observables
of interest for visualization via</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># The DOS can be visualized on the correct energy grid.</span>
<span class="n">density_of_states</span> <span class="o">=</span> <span class="n">ldos_calculator</span><span class="o">.</span><span class="n">density_of_states</span>
<span class="n">energy_grid</span> <span class="o">=</span> <span class="n">ldos_calculator</span><span class="o">.</span><span class="n">energy_grid</span>

<span class="c1"># The density can be saved into a .cube file for visualization with standard</span>
<span class="c1"># electronic structure visualization software.</span>
<span class="n">density_calculator</span> <span class="o">=</span> <span class="n">mala</span><span class="o">.</span><span class="n">Density</span><span class="o">.</span><span class="n">from_ldos_calculator</span><span class="p">(</span><span class="n">ldos_calculator</span><span class="p">)</span>
<span class="n">density_calculator</span><span class="o">.</span><span class="n">write_to_cube</span><span class="p">(</span><span class="s2">&quot;Be_density.cube&quot;</span><span class="p">)</span>

<span class="c1"># The radial distribution function can be visualized on discretized radii.</span>
<span class="n">rdf</span><span class="p">,</span> <span class="n">radii</span> <span class="o">=</span> <span class="n">ldos_calculator</span><span class="o">.</span>\
    <span class="n">radial_distribution_function_from_atoms</span><span class="p">(</span><span class="n">ldos_calculator</span><span class="o">.</span><span class="n">atoms</span><span class="p">,</span>
                                            <span class="n">number_of_bins</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>

<span class="c1"># The static structure factor can be visualized on a discretized k-grid.</span>
<span class="n">static_structure</span><span class="p">,</span> <span class="n">kpoints</span> <span class="o">=</span> <span class="n">ldos_calculator</span><span class="o">.</span>\
    <span class="n">static_structure_factor_from_atoms</span><span class="p">(</span><span class="n">ldos_calculator</span><span class="o">.</span><span class="n">atoms</span><span class="p">,</span>
                                       <span class="n">number_of_bins</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">kMax</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p>With the exception of the electronic density, which is saved into the <code class="docutils literal notranslate"><span class="pre">.cube</span></code>
format for visualization with regular electronic structure visualization
software, all of these observables can be plotted with Python based
visualization libraries such as <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code>.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="hyperparameters.html" class="btn btn-neutral float-left" title="Improved hyperparameter optimization" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../citing.html" class="btn btn-neutral float-right" title="Citing MALA" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021 National Technology &amp; Engineering Solutions of Sandia, LLC (NTESS). Under the terms of Contract DE-NA0003525 with NTESS, the U.S. Government retains certain rights in this software. Attila Cangi, J. Austin Ellis, Lenz Fiedler, Daniel Kotik, Normand Modine, Sivasankaran Rajamanickam, Steve Schmerler, Aidan Thompson.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>